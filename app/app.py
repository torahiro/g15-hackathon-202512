import streamlit as st
import sounddevice as sd
import numpy as np
import time
import json
import os
import threading
import matplotlib.pyplot as plt
import matplotlib
from scipy.signal import butter, lfilter

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦é©å®œå¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
# Mac: AppleGothic, Windows: MS Gothic or Meiryo ãªã©
matplotlib.rcParams['font.family'] = 'AppleGothic'
matplotlib.rcParams['axes.unicode_minus'] = False

# ===== è¨­å®šï¼ˆç§’ï¼‰ =====
TIME_WARNING = 60       # å„ªå…ˆ1: è­¦å‘Š
TIME_SHAME = 180        # æ¥ãšã‹ã—ã„éŸ³
TIME_SPECTATOR = 190    # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰
TIME_TALK_LIMIT = 30    # å„ªå…ˆ2: å–‹ã‚Šã™ããƒšãƒŠãƒ«ãƒ†ã‚£

# ===== éŸ³å£°èªè­˜è¨­å®š =====
SAMPLE_RATE = 44100
CHECK_INTERVAL = 0.1
DEFAULT_THRESHOLD = 0.05
VOICE_BAND = (300, 3400) # äººé–“ã®å£°ã®å‘¨æ³¢æ•°å¸¯åŸŸ

# ===== éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« =====
SOUND_WARNING = "alarm.wav"
SOUND_SHAME = "shame.wav"
SOUND_SPECTATOR = "spectator.wav"
SOUND_TALK_TOO_MUCH = "shame.wav" # ãƒšãƒŠãƒ«ãƒ†ã‚£éŸ³
SOUND_APOLOGY = "apology.wav"

STATE_FILE = "state.json"

# ===== ãƒ•ã‚£ãƒ«ã‚¿é–¢æ•° (observer.pyã‚ˆã‚Šç§»æ¤) =====
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    return lfilter(b, a, data)

# ===== state load/save =====
def read_state():
    try:
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, "r") as f:
                data = json.load(f)
                # æ—¢å­˜ã®JSONã«ã‚­ãƒ¼ãŒãªã„å ´åˆã®å¯¾ç­–
                if "total_talk_time" not in data: data["total_talk_time"] = 0.0
                if "total_silence_time" not in data: data["total_silence_time"] = 0.0
                return data
    except:
        pass
    return {
        "last_voice_time": time.time(),
        "talk_duration": 0.0,
        "threshold": DEFAULT_THRESHOLD,
        "is_spectator": False,
        "current_volume": 0.0,
        "device_id": None,
        "total_talk_time": 0.0,    # ç´¯ç©ä¼šè©±æ™‚é–“
        "total_silence_time": 0.0  # ç´¯ç©ç„¡éŸ³æ™‚é–“
    }

def write_state(updates: dict):
    state = read_state()
    state.update(updates)
    try:
        with open(STATE_FILE, "w") as f:
            json.dump(state, f)
    except:
        pass

# ===== TalkTimer =====
class TalkTimer:
    def __init__(self, penalty_limit=30, silence_tolerance=2.0):
        self.speech_start_time = None
        self.last_sound_time = 0
        self.is_talking_session = False
        self.penalty_limit = penalty_limit
        self.silence_tolerance = silence_tolerance

    def update(self, is_talking_now):
        current_time = time.time()

        if is_talking_now:
            self.last_sound_time = current_time
            if not self.is_talking_session:
                self.is_talking_session = True
                self.speech_start_time = current_time

        elif self.is_talking_session:
            if current_time - self.last_sound_time > self.silence_tolerance:
                self.is_talking_session = False
                self.speech_start_time = None

        if self.is_talking_session and self.speech_start_time:
            return current_time - self.speech_start_time

        return 0.0

# ===== AudioMonitor =====
class AudioMonitor(threading.Thread):
    def __init__(self, sample_rate=44100, interval=0.1, default_threshold=DEFAULT_THRESHOLD):
        super().__init__(daemon=True)
        self.sample_rate = sample_rate
        self.interval = interval
        self.default_threshold = default_threshold
        self.talk_timer = TalkTimer(TIME_TALK_LIMIT, 1.0)
        self.running = True
        self.device_id = None
        
        # ãƒ•ã‚£ãƒ«ã‚¿ä¿‚æ•°ã®äº‹å‰è¨ˆç®—
        self.b, self.a = butter_bandpass(VOICE_BAND[0], VOICE_BAND[1], self.sample_rate)

    def choose_device(self):
        state = read_state()
        dev = state.get("device_id", None)
        if dev is not None:
            self.device_id = dev
            return
        
        # ãªã‘ã‚Œã°BlackHoleãªã©ã‚’æ¢ã™ãŒã€åŸºæœ¬ã¯None(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)ã§å‹•ä½œã•ã›ã‚‹
        try:
            devices = sd.query_devices()
            for i, d in enumerate(devices):
                if "BlackHole" in d["name"]:
                    self.device_id = i
                    write_state({"device_id": i})
                    return
        except:
            pass
        self.device_id = None

    def rms(self, data):
        if data.size == 0:
            return 0.0
        return float(np.sqrt(np.mean(np.square(data.astype(np.float64)))))

    def run(self):
        self.choose_device()
        try:
            with sd.InputStream(device=self.device_id, channels=1, samplerate=self.sample_rate) as stream:
                frames = int(self.sample_rate * self.interval)
                while self.running:
                    try:
                        data, overflow = stream.read(frames)
                    except:
                        time.sleep(0.5)
                        self.choose_device()
                        continue

                    raw_arr = data[:, 0] if data.ndim > 1 else data
                    
                    # â˜…ã“ã“ã§ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ (äººé–“ã®å£°ã ã‘ã‚’é€šã™)
                    filtered_arr = lfilter(self.b, self.a, raw_arr)
                    volume = self.rms(filtered_arr)

                    s = read_state()
                    threshold = s.get("threshold", self.default_threshold)
                    is_spectator = s.get("is_spectator", False)
                    
                    # ç´¯ç©æ™‚é–“ã®æ›´æ–°ç”¨
                    total_talk = s.get("total_talk_time", 0.0)
                    total_silence = s.get("total_silence_time", 0.0)

                    updates = {"current_volume": volume}
                    is_talking_now = (volume > threshold)

                    if not is_spectator:
                        if is_talking_now:
                            updates["last_voice_time"] = time.time()
                            total_talk += self.interval  # ä¼šè©±æ™‚é–“ã‚’åŠ ç®—
                        else:
                            total_silence += self.interval # ç„¡éŸ³æ™‚é–“ã‚’åŠ ç®—
                            
                        updates["talk_duration"] = self.talk_timer.update(is_talking_now)
                    else:
                        self.talk_timer.is_talking_session = False
                        updates["talk_duration"] = 0.0
                        # è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯ç„¡éŸ³ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã‹ã€ã‚«ã‚¦ãƒ³ãƒˆã—ãªã„ã‹ã¯è¦ä»¶æ¬¡ç¬¬
                        # ã“ã“ã§ã¯ã‚«ã‚¦ãƒ³ãƒˆã—ãªã„è¨­å®šã«ã—ã¾ã™

                    # ç´¯ç©æ™‚é–“ã‚’æ›´æ–°
                    updates["total_talk_time"] = total_talk
                    updates["total_silence_time"] = total_silence

                    write_state(updates)
                    time.sleep(self.interval)

        except Exception as e:
            write_state({"current_volume": 0.0})
            print("AudioMonitor stopped:", e)

    def stop(self):
        self.running = False


# ===== Streamlit UI =====
st.set_page_config(page_title="ä¼šè©±ç›£è¦–ãƒœãƒƒãƒˆï¼ˆå®Œå…¨ç‰ˆï¼‰", layout="centered")

if "warning_played" not in st.session_state:
    st.session_state.warning_played = False
if "shame_played" not in st.session_state:
    st.session_state.shame_played = False
if "talk_limit_played" not in st.session_state:
    st.session_state.talk_limit_played = False

# èµ·å‹•æ™‚ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ç›£è¦–ã‚’é–‹å§‹
if "audio_monitor" not in st.session_state:
    st.session_state.audio_monitor = AudioMonitor(SAMPLE_RATE, CHECK_INTERVAL)
    st.session_state.audio_monitor.start()

# state load
state = read_state()
last_voice_time = state["last_voice_time"]
talk_duration = state["talk_duration"]
current_vol = state["current_volume"]
is_spectator = state["is_spectator"]
threshold = state["threshold"]
device_id = state["device_id"]
total_talk_time = state.get("total_talk_time", 0.0)
total_silence_time = state.get("total_silence_time", 0.0)

elapsed_silence = time.time() - last_voice_time

# ===== Sidebar =====
st.sidebar.header("âš™ï¸ è¨­å®š")

# å†ã‚¹ã‚¿ãƒ¼ãƒˆãƒœã‚¿ãƒ³
if "restart_used" not in st.session_state:
    st.session_state.restart_used = False

if not st.session_state.restart_used:
    if st.sidebar.button("å†ã‚¹ã‚¿ãƒ¼ãƒˆ"):
        write_state({
            "is_spectator": False,
            "last_voice_time": time.time(),
            "talk_duration": 0.0,
            "total_talk_time": 0.0,    # ç´¯ç©ã‚‚ãƒªã‚»ãƒƒãƒˆ
            "total_silence_time": 0.0
        })
        st.session_state.warning_played = False
        st.session_state.shame_played = False
        st.session_state.talk_limit_played = False
        st.session_state.restart_used = True
        st.rerun()
else:
    st.sidebar.button("å†ã‚¹ã‚¿ãƒ¼ãƒˆ", disabled=True)

# Device selection
try:
    devices = sd.query_devices()
    names = [f"{i}: {d['name']}" for i, d in enumerate(devices)]
except:
    devices = []
    names = []

if names:
    default_idx = device_id if device_id is not None else 0
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å¤–ã®å ´åˆã®ä¿è­·
    if default_idx >= len(names): default_idx = 0
    
    selected = st.sidebar.selectbox("å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹", names, index=default_idx)
    sel_idx = int(selected.split(":")[0])
    if sel_idx != device_id:
        write_state({"device_id": sel_idx})
        st.session_state.audio_monitor.device_id = sel_idx

new_th = st.sidebar.slider("ãƒã‚¤ã‚¯æ„Ÿåº¦", 0.01, 1.0, threshold, 0.01)
if new_th != threshold:
    write_state({"threshold": new_th})

# ===== Main UI =====
st.title("ã‚·ãƒ£ãƒ™ãƒ­ãƒ¼å›ï¼ˆå®Œå…¨ç‰ˆï¼‰ğŸ—£ï¸ğŸ¤–")

# spectator mode
if is_spectator:
    st.error("ğŸ‘» ã‚ãªãŸã¯è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰ã§ã™")
    st.metric("æ”¾ç½®æ™‚é–“", f"{int(elapsed_silence)} ç§’")
    st.write("---")

    if not os.path.exists(SOUND_APOLOGY):
        st.warning(f"ã€Œ{SOUND_APOLOGY}ã€ãŒç„¡ã„ã®ã§å¾©æ´»ã§ãã¾ã›ã‚“ã€‚")
    else:
        if st.button("è¬ç½ªã—ã¦å¾©æ´»"):
            st.audio(SOUND_APOLOGY, autoplay=True)
            time.sleep(0.3)
            write_state({
                "is_spectator": False,
                "last_voice_time": time.time()
            })
            st.rerun()
else:
    col1, col2 = st.columns(2)
    col1.metric("ç„¡éŸ³æ™‚é–“", f"{int(elapsed_silence)} ç§’")
    col2.metric("é€£ç¶šç™ºè©±", f"{talk_duration:.1f} ç§’")

    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¡ãƒ¼ã‚¿ãƒ¼
    st.progress(min(current_vol / 0.5, 1.0))

    # --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
    
    # å„ªå…ˆ2: 30ç§’ä»¥ä¸Šå–‹ã‚Šç¶šã‘ãŸã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£
    if talk_duration > TIME_TALK_LIMIT:
        st.error(f"ğŸ›‘ å–‹ã‚Šã™ãï¼ï¼ˆ{int(talk_duration)}ç§’ï¼‰")
        if not st.session_state.talk_limit_played:
            if os.path.exists(SOUND_TALK_TOO_MUCH):
                st.audio(SOUND_TALK_TOO_MUCH, autoplay=True)
            st.session_state.talk_limit_played = True

    # 190ç§’ç„¡éŸ³: è¦³æˆ¦ãƒ¢ãƒ¼ãƒ‰
    elif elapsed_silence >= TIME_SPECTATOR:
        write_state({"is_spectator": True})
        if os.path.exists(SOUND_SPECTATOR):
            st.audio(SOUND_SPECTATOR, autoplay=True)
        st.rerun()

    # 180ç§’ç„¡éŸ³: æ¥ãšã‹ã—ã„éŸ³
    elif elapsed_silence >= TIME_SHAME:
        st.warning("ğŸ˜± å±é™ºåŸŸï¼æ¥ãšã‹ã—ã„éŸ³ãŒé³´ã‚Šã¾ã™ï¼")
        if not st.session_state.shame_played:
            if os.path.exists(SOUND_SHAME):
                st.audio(SOUND_SHAME, autoplay=True)
            st.session_state.shame_played = True

    # å„ªå…ˆ1: 60ç§’ç„¡éŸ³: è­¦å‘Š
    elif elapsed_silence >= TIME_WARNING:
        st.info("âš ï¸ ä¼šè©±ãŒæ­¢ã¾ã£ã¦ã„ã¾ã™â€¦")
        if not st.session_state.warning_played:
            if os.path.exists(SOUND_WARNING):
                st.audio(SOUND_WARNING, autoplay=True)
            st.session_state.warning_played = True

    else:
        st.success("âœ… æ­£å¸¸é‹è»¢ä¸­")
        # ãƒ•ãƒ©ã‚°ã®ãƒªã‚»ãƒƒãƒˆ
        if elapsed_silence < 2:
            st.session_state.warning_played = False
            st.session_state.shame_played = False
        if talk_duration < 1:
            st.session_state.talk_limit_played = False

    # ===== å††ã‚°ãƒ©ãƒ•ï¼ˆç´¯ç©ï¼šä¼šè©±æ™‚é–“ vs ç„¡éŸ³æ™‚é–“ï¼‰ =====
    st.subheader("ğŸ“Š ä¼šè©±å‰²åˆï¼ˆç´¯ç©ï¼‰")
    st.write("ğŸŸ¥=è©±ã—ãŸæ™‚é–“")
    st.write("ğŸŸ¦=ç„¡éŸ³æ™‚é–“")
    
    # ãƒ‡ãƒ¼ã‚¿ãŒ0ã ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ã
    if total_talk_time == 0 and total_silence_time == 0:
        sizes = [0, 1] # ãƒ€ãƒŸãƒ¼
        labels = ["è©±ã—ãŸæ™‚é–“", "ç„¡éŸ³æ™‚é–“"]
        colors = ['gray', 'lightgray']
    else:
        sizes = [total_talk_time, total_silence_time]
        labels = ["è©±ã—ãŸæ™‚é–“", "ç„¡éŸ³æ™‚é–“"]
        colors = ['#ff9999', '#66b3ff']

    fig, ax = plt.subplots(figsize=(3, 3))
    ax.pie(sizes, labels=labels, autopct="%1.1f%%", startangle=90, colors=colors)
    ax.axis("equal")  # å††ã‚’ä¸¸ãã™ã‚‹
    # èƒŒæ™¯ã‚’é€æ˜ã«è¿‘ã¥ã‘ã‚‹ï¼ˆStreamlitã®ãƒ†ãƒ¼ãƒã«åˆã‚ã›ã‚‹ãŸã‚ï¼‰
    fig.patch.set_alpha(0)
    
    st.pyplot(fig)

    time.sleep(1)
    st.rerun()

